{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "characters = pd.read_table('data_source/movie_characters_metadata.txt',header=None,sep='\\+\\+\\+\\$\\+\\+\\+',engine='python')\n",
    "characters.columns = ['character_index','character_name','movie_index','movie_name','gender','position of credits']\n",
    "\n",
    "con = pd.read_table('data_source/movie_conversations.txt',header=None,sep='\\+\\+\\+\\$\\+\\+\\+',engine='python')\n",
    "con.columns = ['character_p1','character_p2','movie_index','conversation_index']\n",
    "con_lst = list(con['conversation_index'])\n",
    "con_lst =[ele.replace('[','').replace(']','').replace('\\'','').strip().split(',') for ele in con_lst]\n",
    "con['conversation_index']=pd.Series(con_lst)\n",
    "\n",
    "mlines = pd.read_table('data_source/movie_lines.txt',header=None,sep='\\+\\+\\+\\$\\+\\+\\+',engine='python')\n",
    "mlines.columns = ['line_index','character_index','movie_index','character_name','line']\n",
    "mlines['line_index']=pd.Series([ele.strip() for ele in mlines['line_index']])\n",
    "mlines=mlines.set_index('line_index')\n",
    "\n",
    "con['conversation']=[[str(mlines['line'][idx.strip()]) for idx in ele] for ele in con['conversation_index'] ]\n",
    "con['doc']=pd.Series([''.join(ele) for ele in con['conversation']])\n",
    "con['word_list']= [[word.decode(\"utf8\", errors='ignore') for word in ele.split()] for ele in con['doc']]\n",
    "con['doc']=[' '.join(ele) for ele in con['word_list']]\n",
    "\n",
    "con['corpus'] = pd.Series([''.join(char.lower() for char in ele if char not in '\"#$%&()*+/:;<=>?@[\\\\]^_`{|}~') for ele in con['doc']])\n",
    "\n",
    "mv_names = characters['movie_name'].unique()\n",
    "movie_con = pd.DataFrame(mv_names)\n",
    "movie_con.columns = ['movie_name']\n",
    "movie_content = []\n",
    "mv_lst = con['movie_index'].unique()\n",
    "for movie in mv_lst:\n",
    "    df=con[con['movie_index'] == movie]\n",
    "    movie_content.append(\" \".join( df['corpus']))\n",
    "movie_con['whole_con']=pd.Series(movie_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import nltk.data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "vectors = vectorizer.fit_transform(movie_con['whole_con']).toarray()\n",
    "words = vectorizer.get_feature_names()\n",
    "\n",
    "def get_important_words(lst, n, doc):\n",
    "        '''\n",
    "        INPUT: LIST, INTEGER, LIST\n",
    "        OUTPUT: LIST\n",
    "\n",
    "        Given a list of values, find the indices with the highest n values.\n",
    "        Return the words for each of these indices.\n",
    "\n",
    "        '''\n",
    "        return [doc[i] for i in np.argsort(lst)[-1:-n-1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>whole_con</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 things i hate about you</td>\n",
       "      <td>can we make this quick roxanne korrine and and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1492: conquest of paradise</td>\n",
       "      <td>i never seen heat like this! not even in las m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15 minutes</td>\n",
       "      <td>are you my attorney i'm emil. i'm insane. i'm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001: a space odyssey</td>\n",
       "      <td>space stattion 5 - lounge well, how nice to se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48 hrs.</td>\n",
       "      <td>yeah i want to pick up my car. name hammond. t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     movie_name  \\\n",
       "0   10 things i hate about you    \n",
       "1   1492: conquest of paradise    \n",
       "2                   15 minutes    \n",
       "3        2001: a space odyssey    \n",
       "4                      48 hrs.    \n",
       "\n",
       "                                           whole_con  \n",
       "0  can we make this quick roxanne korrine and and...  \n",
       "1  i never seen heat like this! not even in las m...  \n",
       "2  are you my attorney i'm emil. i'm insane. i'm ...  \n",
       "3  space stattion 5 - lounge well, how nice to se...  \n",
       "4  yeah i want to pick up my car. name hammond. t...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_con.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "women = movie_con[movie_con['movie_name'] == ' quantum project ']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>whole_con</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>quantum project</td>\n",
       "      <td>to isolation. to an armed camp. to a biblical ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            movie_name                                          whole_con\n",
       "486   quantum project   to isolation. to an armed camp. to a biblical ..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "women = get_important_words(vectors[486], 100, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'pauly',\n",
       " u'mia',\n",
       " u'particles',\n",
       " u'did',\n",
       " u'experiment',\n",
       " u'electrons',\n",
       " u'impassable',\n",
       " u'measurements',\n",
       " u'buddhists',\n",
       " u'dysfunctional',\n",
       " u'spoof',\n",
       " u'dreaming',\n",
       " u'parquet',\n",
       " u'defying',\n",
       " u'magically',\n",
       " u'flopped',\n",
       " u'nurture',\n",
       " u'liters',\n",
       " u'perceived',\n",
       " u'downloading',\n",
       " u'unimaginable',\n",
       " u'physicist',\n",
       " u'nothingness',\n",
       " u'obstacle',\n",
       " u'millennium',\n",
       " u'barrier',\n",
       " u'playground',\n",
       " u'didn',\n",
       " u'crazed',\n",
       " u'conductor',\n",
       " u'celebrated',\n",
       " u'input',\n",
       " u'quantum',\n",
       " u'biblical',\n",
       " u'glow',\n",
       " u'isolation',\n",
       " u'classical',\n",
       " u'switching',\n",
       " u'obey',\n",
       " u'relevant',\n",
       " u'atomic',\n",
       " u'miss',\n",
       " u'medication',\n",
       " u'semi',\n",
       " u'eternal',\n",
       " u'physics',\n",
       " u'connect',\n",
       " u'separated',\n",
       " u'want',\n",
       " u'sub',\n",
       " u'logic',\n",
       " u'happily',\n",
       " u'results',\n",
       " u'tunnel',\n",
       " u'firing',\n",
       " u'practical',\n",
       " u'everyday',\n",
       " u'opposite',\n",
       " u'steel',\n",
       " u'town',\n",
       " u'paul',\n",
       " u'bay',\n",
       " u'answer',\n",
       " u'universe',\n",
       " u'charges',\n",
       " u'precious',\n",
       " u'laws',\n",
       " u'camp',\n",
       " u'armed',\n",
       " u'heading',\n",
       " u've',\n",
       " u'connection',\n",
       " u'dunno',\n",
       " u'particular',\n",
       " u'spare',\n",
       " u'level',\n",
       " u'area',\n",
       " u'foot',\n",
       " u'waste',\n",
       " u'wall',\n",
       " u'listening',\n",
       " u'station',\n",
       " u'information',\n",
       " u'ways',\n",
       " u'floor',\n",
       " u'life',\n",
       " u'time',\n",
       " u'middle',\n",
       " u'questions',\n",
       " u'dad',\n",
       " u'gun',\n",
       " u'order',\n",
       " u'seven',\n",
       " u'taken',\n",
       " u'excuse',\n",
       " u'met',\n",
       " u'son',\n",
       " u'inside',\n",
       " u'asked',\n",
       " u'taking']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
